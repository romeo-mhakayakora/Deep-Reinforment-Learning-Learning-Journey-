<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>One-Step Online Actor-Critic  Notes</title>
  <meta name="description" content="Notes and core concepts for one-step online actor-critic (TD(0))." />
  <link rel="stylesheet" href="../assets/styles.css" />
</head>
<body>
  <a class="skip" href="#main">Skip to content</a>

  <header class="site-header">
    <div class="container">
      <div class="brand">
        <p class="brand-title">DeepRL</p>
        <p class="brand-subtitle">actor-critic</p>
      </div>
      <nav class="nav" aria-label="Primary">
        <a href="../">Home</a>
        <a href="./">Actor-Critic</a>
        <a href="../policy-methods/">Policy Methods</a>
        <a href="../value-methods/">Value Methods</a>
        <a href="./one-step-actor-critic-notes.html" aria-current="page">Notes</a>
      </nav>
    </div>
  </header>

  <main id="main" class="container content">
    <article class="prose">
      <h1>ONE-STEP ONLINE ACTOR-CRITIC  CORE CONCEPTS</h1>

      <section class="card">
        <h2>3. TD(0) Advantage (Policy Gradient Signal)</h2>
        <p>The 1-step advantage is the temporal difference error:</p>
        <p><code>A(s_t, a_t) = r_{t+1} + &gamma;V(s_{t+1}) &minus; V(s_t)</code></p>
        <p>In code form:</p>
        <div class="codeblock"><pre><code>advantage = reward + gamma * critic(next_state) - critic(state)</code></pre></div>
        <p>This tells us how much better or worse the taken action was compared to expectation.</p>
      </section>

      <section class="card">
        <h2>4. Actor Loss (Policy Update Objective)</h2>
        <p><code>L_actor = &minus;log &pi;&theta;(a_t|s_t) &middot; A(s_t, a_t)</code></p>
        <p>In code:</p>
        <div class="codeblock"><pre><code>loss_actor = - policy.log_prob(action) * advantage</code></pre></div>

        <h3>Effect of Advantage on Policy</h3>
        <p><code>A &gt; 0</code> &rarr; gradient step increases probability of action <code>a_t</code></p>
        <p><code>A &lt; 0</code> &rarr; gradient step decreases probability of action <code>a_t</code></p>
      </section>

      <section class="card">
        <h2>5. Critic Loss (Value Function Update)</h2>
        <p><code>L_critic = A^2</code></p>
        <p>In code:</p>
        <div class="codeblock"><pre><code>loss_critic = advantage ** 2</code></pre></div>

        <p>More formally, some implementations regress to the 1-step TD target:</p>
        <div class="codeblock"><pre><code>target = reward + gamma * critic(next_state).detach()
loss_critic = (critic(state) - target) ** 2</code></pre></div>

        <p class="meta">(Both express the same TD correction signal; <code>A^2</code> is simply the squared TD error.)</p>
      </section>

      <section class="card">
        <h2>6. Update Rules (Gradient Step)</h2>
        <div class="codeblock"><pre><code>actor_optimizer.zero_grad()
loss_actor.backward()
actor_optimizer.step()

critic_optimizer.zero_grad()
loss_critic.backward()
critic_optimizer.step()</code></pre></div>
      </section>

      <h2>ONE-STEP ONLINE ACTOR-CRITIC  ALGORITHM FLOW</h2>
      <section class="card">
        <ol>
          <li>Observe state <code>s_t</code></li>
          <li>Actor produces policy distribution <code>&pi;(a|s_t)</code></li>
          <li>Sample action <code>a_t ~ &pi;</code></li>
          <li>Execute action in environment</li>
          <li>Observe reward <code>r_{t+1}</code> and next state <code>s_{t+1}</code></li>
          <li>Critic estimates <code>V(s_t)</code> and <code>V(s_{t+1})</code></li>
          <li>Compute advantage (TD error)</li>
          <li>Update actor using <code>&minus;log &pi;(a_t|s_t) * A</code></li>
          <li>Update critic using TD target or squared TD error</li>
          <li>Repeat</li>
        </ol>
      </section>
    </article>
  </main>

  <footer class="site-footer">
    <div class="container">
      <div class="meta">DeepRL  <a href="./">Back to actor-critic</a>  <a href="../">Home</a></div>
    </div>
  </footer>
</body>
</html>
